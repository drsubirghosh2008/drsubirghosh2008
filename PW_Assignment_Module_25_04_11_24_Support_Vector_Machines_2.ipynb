{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6D9SJ1uFZlVcrZCrm3Pw4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drsubirghosh2008/drsubirghosh2008/blob/main/PW_Assignment_Module_25_04_11_24_Support_Vector_Machines_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1. What is the relationship between polynomial functions and kernel functions in machine learning algorithms?\n",
        "\n",
        "Answer:\n",
        "\n",
        "In machine learning, polynomial functions and kernel functions are related through their use in algorithms to map data into higher-dimensional spaces to make it easier to solve complex problems like classification and regression.\n",
        "\n",
        "1. Polynomial Functions in Machine Learning:\n",
        "Polynomial functions are mathematical expressions involving variables raised to powers and their coefficients (e.g.,\n",
        "\n",
        "(\n",
        "\n",
        ")\n",
        "=\n",
        "\n",
        "\n",
        "2\n",
        "+\n",
        "\n",
        "\n",
        "+\n",
        "\n",
        "f(x)=ax\n",
        "2\n",
        " +bx+c).\n",
        "In machine learning, polynomial features can be used to enhance the representational capacity of linear models. For instance, transforming input features to include polynomial terms allows a linear model to fit more complex, non-linear data relationships.\n",
        "2. Kernel Functions:\n",
        "A kernel function is a method used to compute the dot product of two vectors in a transformed feature space without explicitly performing the transformation. This transformation can map data into higher-dimensional space to make it more separable.\n",
        "Kernels are essential in algorithms like Support Vector Machines (SVM), where a linear boundary is sought in a high-dimensional space to classify non-linearly separable data.\n",
        "3. Relationship Between Polynomial Functions and Kernel Functions:\n",
        "Polynomial kernels are a specific type of kernel function. They allow an algorithm to find polynomial decision boundaries without explicitly transforming the original data into a higher-dimensional polynomial space.\n",
        "The polynomial kernel function is defined as:\n",
        "\n",
        "(\n",
        "\n",
        ",\n",
        "\n",
        ")\n",
        "=\n",
        "(\n",
        "\n",
        "\n",
        "\n",
        "+\n",
        "\n",
        ")\n",
        "\n",
        "K(x,y)=(xy+c)\n",
        "d\n",
        "\n",
        "where\n",
        "\n",
        "x and\n",
        "\n",
        "y are input vectors,\n",
        "\n",
        "c is a constant term that allows the flexibility of the kernel, and\n",
        "\n",
        "d is the degree of the polynomial.\n",
        "\n",
        "This kernel computes the dot product of\n",
        "\n",
        "x and\n",
        "\n",
        "y as if they were mapped to a higher-dimensional space containing all polynomial combinations of the input features up to degree\n",
        "\n",
        "d.\n",
        "Summary:\n",
        "The relationship between polynomial functions and kernel functions lies in their use for transforming data to higher-dimensional spaces. Polynomial kernels implicitly perform this transformation, enabling algorithms to learn non-linear relationships without the computational cost of explicit feature expansion. This approach is computationally efficient and forms the basis for the kernel trick used in many algorithms like SVMs."
      ],
      "metadata": {
        "id": "zmzmFxyiPQYk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. How can we implement an SVM with a polynomial kernel in Python using Scikit-learn?\n",
        "\n",
        "Answer:\n",
        "\n",
        "Implementing an SVM with a polynomial kernel in Python using Scikit-learn is straightforward. Scikit-learn provides the SVC class from the sklearn.svm module, which supports various kernel functions, including polynomial kernels. Here's a step-by-step guide and example code:\n",
        "\n",
        "Step-by-Step Implementation:\n",
        "Import the necessary libraries.\n",
        "Load or create a dataset for training and testing.\n",
        "Create an SVM model using the SVC class with kernel='poly'.\n",
        "Train the model using the fit() method.\n",
        "Make predictions and evaluate the model's performance."
      ],
      "metadata": {
        "id": "NoZNMvMMPnrt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example:\n",
        "\n",
        "# Step 1: Import necessary libraries\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Step 2: Load a sample dataset (e.g., the Iris dataset)\n",
        "iris = datasets.load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Step 3: Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Step 4: Create an SVM model with a polynomial kernel\n",
        "svm_poly = SVC(kernel='poly', degree=3, C=1.0, coef0=1)\n",
        "\n",
        "# Step 5: Train the model\n",
        "svm_poly.fit(X_train, y_train)\n",
        "\n",
        "# Step 6: Make predictions\n",
        "y_pred = svm_poly.predict(X_test)\n",
        "\n",
        "# Step 7: Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kM7hnBWsP0yc",
        "outputId": "40d76007-3537-47a4-cdf0-03b27f2326b0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9777777777777777\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        19\n",
            "           1       1.00      0.92      0.96        13\n",
            "           2       0.93      1.00      0.96        13\n",
            "\n",
            "    accuracy                           0.98        45\n",
            "   macro avg       0.98      0.97      0.97        45\n",
            "weighted avg       0.98      0.98      0.98        45\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation:\n",
        "kernel='poly': Specifies the use of a polynomial kernel.\n",
        "degree=3: Sets the degree of the polynomial kernel (can be adjusted as needed).\n",
        "C parameter: Regularization parameter that controls the trade-off between maximizing the margin and minimizing classification errors.\n",
        "coef0: A term added to the polynomial kernel for controlling the influence of higher-degree terms.\n",
        "Key Points:\n",
        "The degree of the polynomial kernel determines how complex the decision boundary can be.\n",
        "You can tune the C, degree, and coef0 parameters to optimize model performance based on your dataset.\n",
        "This example demonstrates how to set up an SVM with a polynomial kernel and evaluate its performance on a dataset."
      ],
      "metadata": {
        "id": "chTyTf5GP7BM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. How does increasing the value of epsilon affect the number of support vectors in SVR?\n",
        "\n",
        "Answer:\n",
        "\n",
        "In Support Vector Regression (SVR), the epsilon (\n",
        "\n",
        "系) parameter plays a crucial role in determining the model's behavior. Here's how it affects the number of support vectors:\n",
        "\n",
        "1. Definition of Epsilon (\n",
        "\n",
        "系) in SVR:\n",
        "The\n",
        "\n",
        "系 parameter defines a margin of tolerance where no penalty is given to errors. In other words, it sets the width of the epsilon-insensitive tube within which predicted values are not penalized for deviating from the actual target values.\n",
        "Only data points that lie outside this\n",
        "\n",
        "系-margin are considered support vectors and contribute to the loss function.\n",
        "2. Effect of Increasing\n",
        "\n",
        "系:\n",
        "Wider Tolerance Margin: As the value of\n",
        "\n",
        "系 increases, the width of the epsilon-insensitive tube becomes larger. This means that more data points can fit within this tube without contributing to the loss function.\n",
        "Fewer Support Vectors: When\n",
        "\n",
        "系 is increased, fewer data points lie outside the epsilon-insensitive region. As a result, fewer data points are treated as support vectors.\n",
        "Simpler Model: With a larger\n",
        "\n",
        "系, the model becomes less sensitive to small variations in the data, leading to a simpler model with potentially less overfitting but potentially higher bias.\n",
        "3. Implications:\n",
        "Trade-off Between Model Complexity and Accuracy: Increasing\n",
        "\n",
        "系 can make the model more robust and less complex by reducing the number of support vectors, but it may also reduce the model's accuracy as it ignores small errors within the tolerance range.\n",
        "Generalization: A larger\n",
        "\n",
        "系 can help in cases where the data has noise, as the model will ignore minor fluctuations and focus on a broader trend. However, if\n",
        "\n",
        "系 is too large, the model might underfit by ignoring meaningful variations.\n",
        "Summary:\n",
        "Increasing the value of\n",
        "\n",
        "系 in SVR generally reduces the number of support vectors because more data points fall within the epsilon-insensitive region and do not contribute to the training objective. This leads to a simpler, more generalized model at the potential cost of decreased precision in fitting the data."
      ],
      "metadata": {
        "id": "_6dsDELeQDBs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter affect the performance of Support Vector Regression (SVR)? Can you explain how each parameter works and provide examples of when you might want to increase or decrease its value?\n",
        "\n",
        "Answer:\n",
        "\n",
        "In Support Vector Regression (SVR), the choice of kernel function and tuning of hyperparameters (\n",
        "\n",
        "C,\n",
        "\n",
        "系, and\n",
        "\n",
        "纬) significantly affect the model's performance. Here's an explanation of how each parameter works and how adjusting them can impact your model:\n",
        "\n",
        "1. Kernel Function:\n",
        "Purpose: The kernel function determines how the input data is mapped into a higher-dimensional space to capture complex relationships.\n",
        "Common Types:\n",
        "Linear Kernel: Used for linearly separable data. Good for simple problems where a linear relationship is sufficient.\n",
        "Polynomial Kernel: Suitable for more complex relationships; allows for polynomial decision boundaries.\n",
        "Radial Basis Function (RBF) Kernel: The most commonly used; it can model non-linear relationships by mapping data into an infinite-dimensional space.\n",
        "Sigmoid Kernel: Sometimes used but not as popular in practice.\n",
        "When to Use:\n",
        "Increase Complexity: Use the RBF or polynomial kernel when the relationship between features and the target is highly non-linear.\n",
        "Reduce Complexity: Use a linear kernel when data is relatively simple or to avoid overfitting with high-dimensional data.\n",
        "2. C Parameter (Regularization):\n",
        "Purpose: Controls the trade-off between fitting the training data well and maintaining a smooth, generalized model.\n",
        "How It Works:\n",
        "A higher\n",
        "\n",
        "C means less regularization, leading to a model that tries to fit the training data as closely as possible, even at the cost of being more complex (low bias, high variance).\n",
        "A lower\n",
        "\n",
        "C increases regularization, making the model less sensitive to individual data points, leading to a smoother, more generalized model (high bias, low variance).\n",
        "When to Adjust:\n",
        "Increase\n",
        "\n",
        "C: When you need the model to better fit the training data and can tolerate overfitting.\n",
        "Decrease\n",
        "\n",
        "C: When you want a simpler model that generalizes better, especially when there is noise in the data.\n",
        "3. Epsilon (\n",
        "\n",
        "系) Parameter:\n",
        "Purpose: Determines the width of the epsilon-insensitive tube, where deviations from the true values are not penalized.\n",
        "How It Works:\n",
        "A smaller\n",
        "\n",
        "系 results in a narrower tube, meaning more points outside the tube become support vectors, increasing model sensitivity and complexity.\n",
        "A larger\n",
        "\n",
        "系 widens the tube, allowing more data points to fall within the no-penalty zone, leading to fewer support vectors and a smoother model.\n",
        "When to Adjust:\n",
        "Increase\n",
        "\n",
        "系: When you want the model to be more robust and tolerant of small deviations, which helps when the data has noise.\n",
        "Decrease\n",
        "\n",
        "系: When you need a more precise fit to the data and can handle potential overfitting.\n",
        "4. Gamma (\n",
        "\n",
        "纬) Parameter (Specific to RBF and Polynomial Kernels):\n",
        "Purpose: Defines how far the influence of a single training point reaches. It controls the \"shape\" of the decision boundary.\n",
        "How It Works:\n",
        "A higher\n",
        "\n",
        "纬 means each point's influence is very localized, creating more complex decision boundaries (low bias, high variance).\n",
        "A lower\n",
        "\n",
        "纬 results in broader influence from each training point, leading to smoother, less complex boundaries (high bias, low variance).\n",
        "When to Adjust:\n",
        "Increase\n",
        "\n",
        "纬: When the data has complex patterns that require tight boundaries to capture.\n",
        "Decrease\n",
        "\n",
        "纬: When you want to reduce overfitting and smooth out the decision boundary for better generalization.\n",
        "Example Scenarios:\n",
        "Noisy Data:\n",
        "Use a higher\n",
        "\n",
        "系 to create a wider tolerance margin and reduce sensitivity to noise.\n",
        "Decrease\n",
        "\n",
        "C to regularize more and avoid overfitting noisy patterns.\n",
        "Complex Non-Linear Relationships:\n",
        "Choose an RBF kernel with a higher\n",
        "\n",
        "纬 to capture intricate patterns.\n",
        "Increase\n",
        "\n",
        "C to allow the model to fit the data more precisely.\n",
        "Smooth, Generalized Model:\n",
        "Use a lower\n",
        "\n",
        "C and a lower\n",
        "\n",
        "纬 with an RBF kernel to make the model less sensitive to individual data points.\n",
        "Increase\n",
        "\n",
        "系 to tolerate minor deviations.\n",
        "Summary:\n",
        "Kernel Function: Choose based on the data's complexity (e.g., RBF for non-linear data).\n",
        "C Parameter: Adjust to balance bias-variance trade-off (higher\n",
        "\n",
        "C for low bias, lower\n",
        "\n",
        "C for high bias).\n",
        "Epsilon Parameter: Set to control the model's tolerance for deviations (larger\n",
        "\n",
        "系 for smoother models).\n",
        "Gamma Parameter: Control the influence range of points in RBF/polynomial kernels (higher\n",
        "\n",
        "纬 for detailed boundaries, lower\n",
        "\n",
        "纬 for smoother ones).\n",
        "Understanding and fine-tuning these parameters helps in creating an SVR model that fits the data appropriately and generalizes well to unseen data."
      ],
      "metadata": {
        "id": "W0pbTKthQPk0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5. Assignment:\n",
        "* Import the necessary libraries and load the dataseg\n",
        "* Split the dataset into training and testing setZ\n",
        "* Preprocess the data using any technique of your choice (e.g. scaling, normalizationK\n",
        "* Create an instance of the SVC classifier and train it on the training datW\n",
        "* Use the trained classifier to predict the labels of the testing datW\n",
        "* Evaluate the performance of the classifier using any metric of your choice (e.g. accuracy, precision, recall, F1-scoreK\n",
        "* Tune the hyperparameters of the SVC classifier using GridSearchCV or RandomizedSearchCV to improve its performanc_\n",
        "* Train the tuned classifier on the entire dataseg\n",
        "* Save the trained classifier to a file for future use.\n",
        "\n",
        "You can use any dataset of your choice for this assignment, but make sure it is suitable for classification and has a sufficient number of features and samples.\n",
        "\n",
        "Answer:\n",
        "\n",
        "Heres a step-by-step guide to completing the assignment using the Iris dataset, a well-known dataset for classification tasks. The code will cover loading the dataset, preprocessing, training an SVC classifier, evaluating its performance, tuning hyperparameters, and saving the model for future use."
      ],
      "metadata": {
        "id": "lqWTNKgWQmhs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ... (previous code) ...\n",
        "\n",
        "# Step 9: Train the tuned classifier on the entire dataset\n",
        "best_svc = grid_search.best_estimator_\n",
        "X_scaled = scaler.fit_transform(X) # Scale the entire dataset X and assign it to X_scaled\n",
        "best_svc.fit(X_scaled, y)\n",
        "\n",
        "# ... (rest of the code) ..."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "Se0HSynoRmk0",
        "outputId": "6263b4eb-e294-4854-ed57-82d4c5255675"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=10, kernel='linear')"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=10, kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;SVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(C=10, kernel=&#x27;linear&#x27;)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import the necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import joblib  # For saving the model\n",
        "\n",
        "# Step 2: Load the dataset\n",
        "iris = datasets.load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Step 3: Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Step 4: Preprocess the data using Standard Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Step 5: Create an instance of the SVC classifier and train it on the training data\n",
        "svc = SVC()\n",
        "svc.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Step 6: Use the trained classifier to predict the labels of the testing data\n",
        "y_pred = svc.predict(X_test_scaled)\n",
        "\n",
        "# Step 7: Evaluate the performance of the classifier\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Step 8: Tune the hyperparameters of the SVC classifier using GridSearchCV\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'kernel': ['linear', 'poly', 'rbf'],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(SVC(), param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Step 9: Train the tuned classifier on the entire dataset\n",
        "best_svc = grid_search.best_estimator_\n",
        "best_svc.fit(X_scaled, y)\n",
        "\n",
        "# Step 10: Save the trained classifier to a file for future use\n",
        "joblib.dump(best_svc, 'best_svc_model.pkl')\n",
        "\n",
        "print(\"Best parameters found:\", grid_search.best_params_)\n",
        "print(\"Best cross-validation accuracy:\", grid_search.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y02eW7kcRUW8",
        "outputId": "3d9c07f0-756f-4d1e-b1bf-429fc3ff36c4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        19\n",
            "           1       1.00      1.00      1.00        13\n",
            "           2       1.00      1.00      1.00        13\n",
            "\n",
            "    accuracy                           1.00        45\n",
            "   macro avg       1.00      1.00      1.00        45\n",
            "weighted avg       1.00      1.00      1.00        45\n",
            "\n",
            "Best parameters found: {'C': 10, 'gamma': 'scale', 'kernel': 'linear'}\n",
            "Best cross-validation accuracy: 0.9523809523809523\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code Explanation:\n",
        "Import Libraries: Necessary libraries for data handling, model building, evaluation, and saving models are imported.\n",
        "\n",
        "Load Dataset: The Iris dataset is loaded using sklearn.datasets.\n",
        "\n",
        "Split Dataset: The dataset is divided into training (70%) and testing (30%) sets.\n",
        "\n",
        "Preprocess Data: Standard scaling is applied to normalize the features, improving SVC's performance.\n",
        "\n",
        "Create and Train Classifier: An instance of SVC is created and fitted to the training data.\n",
        "\n",
        "Prediction: The model predicts labels for the testing data.\n",
        "\n",
        "Performance Evaluation: Model performance is evaluated using accuracy and a classification report.\n",
        "\n",
        "Hyperparameter Tuning: GridSearchCV is used to search for the best hyperparameters for the SVC classifier using cross-validation.\n",
        "\n",
        "Train Tuned Classifier: The best estimator from grid search is trained on the entire dataset.\n",
        "\n",
        "Save the Model: The trained model is saved to a file using joblib.dump.\n",
        "\n",
        "Additional Considerations:\n",
        "The parameters for hyperparameter tuning (param_grid) can be adjusted based on the dataset's characteristics and desired performance.\n",
        "You can also visualize the classification results or feature importance if applicable.\n",
        "Ensure you have installed the necessary libraries (scikit-learn, numpy, pandas, and joblib) before running the code.\n",
        "This process provides a complete workflow for building an SVC classifier, including tuning and saving the model for future use."
      ],
      "metadata": {
        "id": "V_8Ow67wRfxs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Thank You!**"
      ],
      "metadata": {
        "id": "7RppP1WURwHm"
      }
    }
  ]
}