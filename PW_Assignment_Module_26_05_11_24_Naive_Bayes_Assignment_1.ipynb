{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMaSXr1K3issqesyz/xI8rj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drsubirghosh2008/drsubirghosh2008/blob/main/PW_Assignment_Module_26_05_11_24_Naive_Bayes_Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1. What is Bayes' theorem?\n",
        "\n",
        "Answer:\n",
        "Bayes' theorem is a mathematical formula used in probability and statistics to update the probability of an event based on new evidence. It relates the conditional and marginal probabilities of random events. Bayes' theorem is named after Thomas Bayes, an 18th-century statistician and theologian.\n",
        "\n",
        "The theorem is expressed as:\n",
        "\n",
        "𝑃\n",
        "(\n",
        "𝐴\n",
        "∣\n",
        "𝐵\n",
        ")\n",
        "=\n",
        "𝑃\n",
        "(\n",
        "𝐵\n",
        "∣\n",
        "𝐴\n",
        ")\n",
        "⋅\n",
        "𝑃\n",
        "(\n",
        "𝐴\n",
        ")\n",
        "𝑃\n",
        "(\n",
        "𝐵\n",
        ")\n",
        "P(A∣B)=\n",
        "P(B)\n",
        "P(B∣A)⋅P(A)\n",
        "​\n",
        "\n",
        "where:\n",
        "\n",
        "𝑃\n",
        "(\n",
        "𝐴\n",
        "∣\n",
        "𝐵\n",
        ")\n",
        "P(A∣B) is the posterior probability, or the probability of event\n",
        "𝐴\n",
        "A occurring given that\n",
        "𝐵\n",
        "B is true.\n",
        "𝑃\n",
        "(\n",
        "𝐵\n",
        "∣\n",
        "𝐴\n",
        ")\n",
        "P(B∣A) is the likelihood, or the probability of observing\n",
        "𝐵\n",
        "B given that\n",
        "𝐴\n",
        "A is true.\n",
        "𝑃\n",
        "(\n",
        "𝐴\n",
        ")\n",
        "P(A) is the prior probability of\n",
        "𝐴\n",
        "A, the initial probability of event\n",
        "𝐴\n",
        "A occurring.\n",
        "𝑃\n",
        "(\n",
        "𝐵\n",
        ")\n",
        "P(B) is the marginal probability of\n",
        "𝐵\n",
        "B, or the probability of observing\n",
        "𝐵\n",
        "B under all possible conditions.\n",
        "Explanation\n",
        "Bayes' theorem allows us to update our beliefs about the probability of an event (the \"posterior\") based on new evidence, which is especially useful when direct probabilities are difficult to determine. The theorem is widely applied in fields like medicine, finance, machine learning, and more.\n",
        "\n",
        "Example\n",
        "If you have a medical test for a disease:\n",
        "\n",
        "𝐴\n",
        "A = person has the disease\n",
        "𝐵\n",
        "B = test result is positive\n",
        "Using Bayes' theorem, you can calculate the probability that a person actually has the disease given a positive test result, accounting for factors like false positives and the base rate of the disease.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Hl27aM4cLmKh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. What is the formula for Bayes' theorem?\n",
        "\n",
        "Answer:\n",
        "\n",
        "\n",
        "The formula for Bayes' theorem is:\n",
        "\n",
        "𝑃\n",
        "(\n",
        "𝐴\n",
        "∣\n",
        "𝐵\n",
        ")\n",
        "=\n",
        "𝑃\n",
        "(\n",
        "𝐵\n",
        "∣\n",
        "𝐴\n",
        ")\n",
        "⋅\n",
        "𝑃\n",
        "(\n",
        "𝐴\n",
        ")\n",
        "𝑃\n",
        "(\n",
        "𝐵\n",
        ")\n",
        "P(A∣B)=\n",
        "P(B)\n",
        "P(B∣A)⋅P(A)\n",
        "​\n",
        "\n",
        "where:\n",
        "\n",
        "𝑃\n",
        "(\n",
        "𝐴\n",
        "∣\n",
        "𝐵\n",
        ")\n",
        "P(A∣B) = Posterior probability: the probability of event\n",
        "𝐴\n",
        "A occurring given that\n",
        "𝐵\n",
        "B is true.\n",
        "𝑃\n",
        "(\n",
        "𝐵\n",
        "∣\n",
        "𝐴\n",
        ")\n",
        "P(B∣A) = Likelihood: the probability of observing\n",
        "𝐵\n",
        "B given that\n",
        "𝐴\n",
        "A is true.\n",
        "𝑃\n",
        "(\n",
        "𝐴\n",
        ")\n",
        "P(A) = Prior probability of\n",
        "𝐴\n",
        "A: the initial or prior probability of\n",
        "𝐴\n",
        "A occurring.\n",
        "𝑃\n",
        "(\n",
        "𝐵\n",
        ")\n",
        "P(B) = Marginal probability of\n",
        "𝐵\n",
        "B: the probability of observing\n",
        "𝐵\n",
        "B across all possible events.\n",
        "This formula is used to update the probability of an event (\n",
        "𝐴\n",
        "A ) in light of new evidence (\n",
        "𝐵\n",
        "B )."
      ],
      "metadata": {
        "id": "iejaZL40NoRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. How is Bayes' theorem used in practice?\n",
        "\n",
        "Answer:\n",
        "\n",
        "Bayes' theorem is widely used in practice to update probabilities based on new data or evidence. Here are some common applications:\n",
        "\n",
        "1. Medical Diagnosis\n",
        "Goal: To determine the likelihood of a patient having a disease based on test results.\n",
        "Application: Given the prior probability of the disease (prevalence in the population), the sensitivity (true positive rate), and the specificity (true negative rate) of a medical test, Bayes' theorem helps update the probability of having the disease after receiving a positive test result. This helps in understanding the real probability of the disease presence, considering the chances of false positives and false negatives.\n",
        "2. Spam Filtering\n",
        "Goal: To classify emails as spam or not spam.\n",
        "Application: Spam filters use Bayes' theorem to calculate the probability that an email is spam based on words or phrases it contains. The filter learns over time from previous examples of spam and non-spam emails, updating its \"belief\" in real-time based on the email content.\n",
        "3. Machine Learning (Naive Bayes Classifier)\n",
        "Goal: To classify data into categories.\n",
        "Application: Naive Bayes classifiers assume independence between features and use Bayes' theorem to calculate the probability that a data point belongs to a particular class. This technique is popular for text classification tasks, such as sentiment analysis or document categorization, where the model updates probabilities based on each new data point.\n",
        "4. Predictive Text and Autocomplete\n",
        "Goal: To predict what the user is likely to type next.\n",
        "Application: Based on the user’s previous text input and the probability of certain words following others, autocomplete features in messaging and search engines use Bayes' theorem to suggest likely completions.\n",
        "5. Fraud Detection\n",
        "Goal: To detect fraudulent transactions.\n",
        "Application: Banks and payment platforms use Bayes' theorem to calculate the probability that a transaction is fraudulent, given certain risk factors (e.g., unusually large transaction amount, foreign location). By constantly updating probabilities based on new patterns, it can help identify and prevent fraud in real-time.\n",
        "6. Weather Forecasting\n",
        "Goal: To improve the accuracy of weather predictions.\n",
        "Application: Bayes' theorem is used to update the probability of specific weather conditions based on new data (e.g., changes in atmospheric pressure, temperature readings). It can combine prior historical data with new evidence to refine forecasts.\n",
        "7. Genetics and Ancestry Analysis\n",
        "Goal: To determine the likelihood of inheriting specific genes or ancestry traits.\n",
        "Application: Given data on genetic markers, Bayes' theorem is applied to update probabilities for traits, diseases, or ancestry origins based on genetic information, considering prior population-level probabilities.\n",
        "In all these cases, Bayes' theorem is valuable for integrating new evidence to refine predictions or diagnoses, making it essential for areas that involve uncertain outcomes and incomplete data."
      ],
      "metadata": {
        "id": "Hb2DHZ6iOH0X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. What is the relationship between Bayes' theorem and conditional probability?\n",
        "\n",
        "Answer:\n",
        "\n",
        "Bayes' theorem is fundamentally based on conditional probability and provides a way to calculate the probability of an event given that another event has occurred. Conditional probability is the probability of one event happening under the condition that another event has occurred, denoted as\n",
        "𝑃\n",
        "(\n",
        "𝐴\n",
        "∣\n",
        "𝐵\n",
        ")\n",
        "P(A∣B), which reads as \"the probability of\n",
        "𝐴\n",
        "A given\n",
        "𝐵\n",
        "B.\"\n",
        "\n",
        "Relationship Details:\n",
        "Conditional Probability Basis:\n",
        "Bayes' theorem builds on the concept of conditional probability by reversing the condition. For instance, if we know\n",
        "𝑃\n",
        "(\n",
        "𝐵\n",
        "∣\n",
        "𝐴\n",
        ")\n",
        "P(B∣A) — the probability of\n",
        "𝐵\n",
        "B occurring given that\n",
        "𝐴\n",
        "A is true — Bayes' theorem allows us to find\n",
        "𝑃\n",
        "(\n",
        "𝐴\n",
        "∣\n",
        "𝐵\n",
        ")\n",
        "P(A∣B), the probability of\n",
        "𝐴\n",
        "A given that\n",
        "𝐵\n",
        "B is observed.\n",
        "\n",
        "Formula Foundation: Conditional probability is defined as:\n",
        "\n",
        "𝑃\n",
        "(\n",
        "𝐴\n",
        "∣\n",
        "𝐵\n",
        ")\n",
        "=\n",
        "𝑃\n",
        "(\n",
        "𝐴\n",
        "∩\n",
        "𝐵\n",
        ")\n",
        "𝑃\n",
        "(\n",
        "𝐵\n",
        ")\n",
        "P(A∣B)=\n",
        "P(B)\n",
        "P(A∩B)\n",
        "​\n",
        "\n",
        "where\n",
        "𝑃\n",
        "(\n",
        "𝐴\n",
        "∩\n",
        "𝐵\n",
        ")\n",
        "P(A∩B) is the probability of both\n",
        "𝐴\n",
        "A and\n",
        "𝐵\n",
        "B happening. Bayes' theorem rearranges this using the fact that\n",
        "𝑃\n",
        "(\n",
        "𝐴\n",
        "∩\n",
        "𝐵\n",
        ")\n",
        "=\n",
        "𝑃\n",
        "(\n",
        "𝐵\n",
        "∣\n",
        "𝐴\n",
        ")\n",
        "⋅\n",
        "𝑃\n",
        "(\n",
        "𝐴\n",
        ")\n",
        "P(A∩B)=P(B∣A)⋅P(A) to yield:\n",
        "\n",
        "𝑃\n",
        "(\n",
        "𝐴\n",
        "∣\n",
        "𝐵\n",
        ")\n",
        "=\n",
        "𝑃\n",
        "(\n",
        "𝐵\n",
        "∣\n",
        "𝐴\n",
        ")\n",
        "⋅\n",
        "𝑃\n",
        "(\n",
        "𝐴\n",
        ")\n",
        "𝑃\n",
        "(\n",
        "𝐵\n",
        ")\n",
        "P(A∣B)=\n",
        "P(B)\n",
        "P(B∣A)⋅P(A)\n",
        "​\n",
        "\n",
        "Updating Beliefs with New Information: While conditional probability measures the likelihood of one event given another, Bayes' theorem uses it to update the probability of an event (the \"posterior probability\") after observing new evidence. This is particularly useful in situations where direct calculation of\n",
        "𝑃\n",
        "(\n",
        "𝐴\n",
        "∣\n",
        "𝐵\n",
        ")\n",
        "P(A∣B) is challenging but\n",
        "𝑃\n",
        "(\n",
        "𝐵\n",
        "∣\n",
        "𝐴\n",
        ")\n",
        "P(B∣A) and other values are easier to obtain.\n",
        "\n",
        "Symmetry of Probability Interpretation: Bayes' theorem demonstrates that the relationship between two events\n",
        "𝐴\n",
        "A and\n",
        "𝐵\n",
        "B can be viewed from either perspective:\n",
        "\n",
        "𝑃\n",
        "(\n",
        "𝐴\n",
        "∣\n",
        "𝐵\n",
        ")\n",
        "P(A∣B) represents the updated probability of\n",
        "𝐴\n",
        "A when\n",
        "𝐵\n",
        "B is known.\n",
        "𝑃\n",
        "(\n",
        "𝐵\n",
        "∣\n",
        "𝐴\n",
        ")\n",
        "P(B∣A) represents the probability of observing\n",
        "𝐵\n",
        "B if\n",
        "𝐴\n",
        "A were true.\n",
        "In Summary:\n",
        "Bayes' theorem extends conditional probability by providing a structured way to \"flip\" conditions between two events. It shows that conditional probabilities can be recalculated from one known perspective to another, allowing us to infer updated probabilities for one event given evidence about another."
      ],
      "metadata": {
        "id": "7bz6PqRIOa5_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?\n",
        "\n",
        "Answer:\n",
        "\n",
        "Choosing the right type of Naive Bayes classifier depends on the nature of the data, specifically on the type and distribution of features in the dataset. Here’s an overview of the most commonly used Naive Bayes classifiers and how to select one for a given problem:\n",
        "\n",
        "1. Gaussian Naive Bayes\n",
        "Best for: Continuous, normally (Gaussian) distributed data.\n",
        "Application: Use this classifier when features are continuous and approximately follow a normal (Gaussian) distribution. Gaussian Naive Bayes assumes that the continuous values associated with each class are distributed according to a Gaussian distribution.\n",
        "Examples: Suitable for datasets with features like age, height, weight, or other measurements that might follow a bell curve, such as in image recognition and some natural language processing applications where data is continuous.\n",
        "2. Multinomial Naive Bayes\n",
        "Best for: Discrete, count-based data (non-negative integers).\n",
        "Application: This classifier is ideal for discrete features representing counts, such as word frequency counts in text data. It assumes that features are drawn from a multinomial distribution, making it well-suited for text classification tasks where the features are word counts or term frequencies.\n",
        "Examples: Frequently used in text classification problems (e.g., spam detection, document categorization, sentiment analysis), where features are based on word frequencies or term-frequency inverse document frequency (TF-IDF) values.\n",
        "3. Bernoulli Naive Bayes\n",
        "Best for: Binary/Boolean data (0/1 values).\n",
        "Application: This classifier is best when features are binary (0 or 1), indicating the presence or absence of a feature. Bernoulli Naive Bayes assumes that each feature is binary and follows a Bernoulli distribution, making it suitable for tasks where features are binary indicators.\n",
        "Examples: Also popular in text classification but for binary term occurrence indicators (e.g., whether a particular word appears in a document or not). It is also used in image recognition, where pixels are represented in a binary format.\n",
        "Choosing the Right Naive Bayes Model\n",
        "Continuous Data: If your dataset has continuous features and they approximately follow a normal distribution, Gaussian Naive Bayes is usually a good choice.\n",
        "Discrete Count Data: For tasks with count data, such as word frequencies in text analysis, Multinomial Naive Bayes is ideal.\n",
        "Binary Data: If your features are binary (presence/absence), then Bernoulli Naive Bayes is most appropriate.\n",
        "In summary:\n",
        "\n",
        "Use Gaussian Naive Bayes for continuous data that approximates a normal distribution.\n",
        "Use Multinomial Naive Bayes for count data, especially in text classification.\n",
        "Use Bernoulli Naive Bayes for binary data, particularly in text and image classification with binary features.\n",
        "\n",
        "Additional Considerations\n",
        "\n",
        "Experimenting with different types can be helpful, as the assumptions of each model may vary slightly from real data distributions. However, understanding the nature of your feature data is the primary guide for selecting the most suitable Naive Bayes classifier."
      ],
      "metadata": {
        "id": "EmnUeMwaOxH2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6. Assignment:\n",
        "You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of each feature value for each class:\n",
        "\n",
        "Class X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4\n",
        "A      3    3     4   4    3    3    3\n",
        "B      2    2     1   2    2    2    3\n",
        "Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance to belong to?\n",
        "\n",
        "Answer:\n",
        "\n",
        "o determine the predicted class for a new instance with\n",
        "𝑋\n",
        "1\n",
        "=\n",
        "3\n",
        "X1=3 and\n",
        "𝑋\n",
        "2\n",
        "=\n",
        "4\n",
        "X2=4, we'll use Naive Bayes by calculating the posterior probability of each class (A and B) given the feature values\n",
        "𝑋\n",
        "1\n",
        "=\n",
        "3\n",
        "X1=3 and\n",
        "𝑋\n",
        "2\n",
        "=\n",
        "4\n",
        "X2=4.\n",
        "\n",
        "Step-by-Step Solution:\n",
        "Calculate the Prior Probabilities: Since the prior probabilities for each class are equal, we have:\n",
        "\n",
        "𝑃\n",
        "(\n",
        "𝐴\n",
        ")\n",
        "=\n",
        "𝑃\n",
        "(\n",
        "𝐵\n",
        ")\n",
        "=\n",
        "0.5\n",
        "P(A)=P(B)=0.5\n",
        "Calculate the Likelihoods:\n",
        "\n",
        "For each class, we need to calculate\n",
        "𝑃\n",
        "(\n",
        "𝑋\n",
        "1\n",
        "=\n",
        "3\n",
        "∣\n",
        "Class\n",
        ")\n",
        "P(X1=3∣Class) and\n",
        "𝑃\n",
        "(\n",
        "𝑋\n",
        "2\n",
        "=\n",
        "4\n",
        "∣\n",
        "Class\n",
        ")\n",
        "P(X2=4∣Class).\n",
        "\n",
        "From the table, we can extract the likelihoods:\n",
        "\n",
        "For Class A:\n",
        "\n",
        "𝑃\n",
        "(\n",
        "𝑋\n",
        "1\n",
        "=\n",
        "3\n",
        "∣\n",
        "𝐴\n",
        ")\n",
        "=\n",
        "Frequency of\n",
        "𝑋\n",
        "1\n",
        "=\n",
        "3\n",
        " for A\n",
        "Total frequency of A for\n",
        "𝑋\n",
        "1\n",
        "=\n",
        "4\n",
        "3\n",
        "+\n",
        "3\n",
        "+\n",
        "4\n",
        "=\n",
        "4\n",
        "10\n",
        "=\n",
        "0.4\n",
        "P(X1=3∣A)=\n",
        "Total frequency of A for X1\n",
        "Frequency of X1=3 for A\n",
        "​\n",
        " =\n",
        "3+3+4\n",
        "4\n",
        "​\n",
        " =\n",
        "10\n",
        "4\n",
        "​\n",
        " =0.4\n",
        "𝑃\n",
        "(\n",
        "𝑋\n",
        "2\n",
        "=\n",
        "4\n",
        "∣\n",
        "𝐴\n",
        ")\n",
        "=\n",
        "Frequency of\n",
        "𝑋\n",
        "2\n",
        "=\n",
        "4\n",
        " for A\n",
        "Total frequency of A for\n",
        "𝑋\n",
        "2\n",
        "=\n",
        "3\n",
        "4\n",
        "+\n",
        "3\n",
        "+\n",
        "3\n",
        "+\n",
        "3\n",
        "=\n",
        "3\n",
        "13\n",
        "P(X2=4∣A)=\n",
        "Total frequency of A for X2\n",
        "Frequency of X2=4 for A\n",
        "​\n",
        " =\n",
        "4+3+3+3\n",
        "3\n",
        "​\n",
        " =\n",
        "13\n",
        "3\n",
        "​\n",
        "\n",
        "For Class B:\n",
        "\n",
        "P(X1 = 3 | B) = \\frac{\\text{Frequency of } X1 = 3 \\text{ for B}}{\\text{Total frequency of B for } X1} = \\frac{1}{\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "riIAoj_YPPS2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Thank You!**"
      ],
      "metadata": {
        "id": "VE3L3n_tQhjv"
      }
    }
  ]
}