{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdsxXI8BtV0AntMwuVEwme",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drsubirghosh2008/drsubirghosh2008/blob/main/PW_Assignment_Module_31_22_11_24_ML_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create and deploy a ML project by importing load_breast_cancer dataset from sklearn.load_dataset and\n",
        "apply the following:\n"
      ],
      "metadata": {
        "id": "bYUIdbech-GP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Create a folder in which you want to create the project, after that use the git init and the necessary commands to create the specific Git repository\n",
        "\n",
        "Answer:"
      ],
      "metadata": {
        "id": "6NCU6_sWtq1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score"
      ],
      "metadata": {
        "id": "EwyMdCxzw7vl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target, name='target')"
      ],
      "metadata": {
        "id": "plr9uxwrw8aM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKFfP7PxxcpG",
        "outputId": "2e4dbaaa-1cab-4649-d33c-232484eb4df0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
              "         1.189e-01],\n",
              "        [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
              "         8.902e-02],\n",
              "        [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
              "         8.758e-02],\n",
              "        ...,\n",
              "        [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
              "         7.820e-02],\n",
              "        [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
              "         1.240e-01],\n",
              "        [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
              "         7.039e-02]]),\n",
              " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
              "        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
              "        0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
              "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
              "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]),\n",
              " 'frame': None,\n",
              " 'target_names': array(['malignant', 'benign'], dtype='<U9'),\n",
              " 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n:Number of Instances: 569\\n\\n:Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n:Attribute Information:\\n    - radius (mean of distances from center to points on the perimeter)\\n    - texture (standard deviation of gray-scale values)\\n    - perimeter\\n    - area\\n    - smoothness (local variation in radius lengths)\\n    - compactness (perimeter^2 / area - 1.0)\\n    - concavity (severity of concave portions of the contour)\\n    - concave points (number of concave portions of the contour)\\n    - symmetry\\n    - fractal dimension (\"coastline approximation\" - 1)\\n\\n    The mean, standard error, and \"worst\" or largest (mean of the three\\n    worst/largest values) of these features were computed for each image,\\n    resulting in 30 features.  For instance, field 0 is Mean Radius, field\\n    10 is Radius SE, field 20 is Worst Radius.\\n\\n    - class:\\n            - WDBC-Malignant\\n            - WDBC-Benign\\n\\n:Summary Statistics:\\n\\n===================================== ====== ======\\n                                        Min    Max\\n===================================== ====== ======\\nradius (mean):                        6.981  28.11\\ntexture (mean):                       9.71   39.28\\nperimeter (mean):                     43.79  188.5\\narea (mean):                          143.5  2501.0\\nsmoothness (mean):                    0.053  0.163\\ncompactness (mean):                   0.019  0.345\\nconcavity (mean):                     0.0    0.427\\nconcave points (mean):                0.0    0.201\\nsymmetry (mean):                      0.106  0.304\\nfractal dimension (mean):             0.05   0.097\\nradius (standard error):              0.112  2.873\\ntexture (standard error):             0.36   4.885\\nperimeter (standard error):           0.757  21.98\\narea (standard error):                6.802  542.2\\nsmoothness (standard error):          0.002  0.031\\ncompactness (standard error):         0.002  0.135\\nconcavity (standard error):           0.0    0.396\\nconcave points (standard error):      0.0    0.053\\nsymmetry (standard error):            0.008  0.079\\nfractal dimension (standard error):   0.001  0.03\\nradius (worst):                       7.93   36.04\\ntexture (worst):                      12.02  49.54\\nperimeter (worst):                    50.41  251.2\\narea (worst):                         185.2  4254.0\\nsmoothness (worst):                   0.071  0.223\\ncompactness (worst):                  0.027  1.058\\nconcavity (worst):                    0.0    1.252\\nconcave points (worst):               0.0    0.291\\nsymmetry (worst):                     0.156  0.664\\nfractal dimension (worst):            0.055  0.208\\n===================================== ====== ======\\n\\n:Missing Attribute Values: None\\n\\n:Class Distribution: 212 - Malignant, 357 - Benign\\n\\n:Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n:Donor: Nick Street\\n\\n:Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. dropdown:: References\\n\\n  - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction\\n    for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on\\n    Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n    San Jose, CA, 1993.\\n  - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and\\n    prognosis via linear programming. Operations Research, 43(4), pages 570-577,\\n    July-August 1995.\\n  - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n    to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994)\\n    163-171.\\n',\n",
              " 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
              "        'mean smoothness', 'mean compactness', 'mean concavity',\n",
              "        'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
              "        'radius error', 'texture error', 'perimeter error', 'area error',\n",
              "        'smoothness error', 'compactness error', 'concavity error',\n",
              "        'concave points error', 'symmetry error',\n",
              "        'fractal dimension error', 'worst radius', 'worst texture',\n",
              "        'worst perimeter', 'worst area', 'worst smoothness',\n",
              "        'worst compactness', 'worst concavity', 'worst concave points',\n",
              "        'worst symmetry', 'worst fractal dimension'], dtype='<U23'),\n",
              " 'filename': 'breast_cancer.csv',\n",
              " 'data_module': 'sklearn.datasets.data'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "sP5VgVITw8d1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "i-zbqOy8w8he",
        "outputId": "ce0b1c2c-163a-4408-9bcd-98aef7e71212"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(random_state=42)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "Zl68dLr1xJp_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfT8Fdq5xJuY",
        "outputId": "1b98a96e-c19f-48ae-db99-46d28c5917ac"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9649122807017544\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.93      0.95        43\n",
            "           1       0.96      0.99      0.97        71\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.97      0.96      0.96       114\n",
            "weighted avg       0.97      0.96      0.96       114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. H Create a separate environment so that you do not mess up with your base environment\n",
        "\n",
        "Answer:\n",
        "\n",
        "Step 1: Create a Separate Environment\n",
        "\n",
        "Step 2: Install Required Dependencies\n",
        "\n",
        "Step 3: Verify the Environment Setup\n",
        "\n",
        "Step 4: Deactivate the Environment\n",
        "\n",
        "Step 5: Document Environment Setup"
      ],
      "metadata": {
        "id": "mn1W_hzbxsaG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3.  Create the folder structure/directories and files using the python programme required for a ML project.\n",
        "You can refer the following project structureF\n",
        "< sr3\n",
        ", __init__.p*\n",
        ", logger.p*\n",
        ", exception.p*\n",
        ", utils.p*\n",
        ", component5\n",
        ", __init__.p*\n",
        ", data_ingestion.p*\n",
        ", data_transformation.p*\n",
        ", model_trainer.p*\n",
        ", pipelin4\n",
        ", __init__.p*\n",
        ", predict_pipeline.p*\n",
        ", train_pipeline.p*\n",
        "< import_data.p*\n",
        "< setup.p*\n",
        "< noteboo+\n",
        "< requirements.txt\n",
        "After this update the created folders and files to your git repository by pushing from your end and add\n",
        "following files from github and pull it to your source codeF\n",
        ", README.m!\n",
        ", LICENS\n",
        ", .gitignor4\n",
        "\n",
        "Answer:\n",
        "\n",
        "Python Program to Create the Folder Structure"
      ],
      "metadata": {
        "id": "836tx26E3Kjj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def create_ml_project_structure(base_dir):\n",
        "    # Create base project directory\n",
        "    os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "    # Subdirectories and files\n",
        "    directories = {\n",
        "        \"src\": [\n",
        "            \"__init__.py\",\n",
        "            \"logger.py\",\n",
        "            \"exception.py\",\n",
        "            \"utils.py\"\n",
        "        ],\n",
        "        \"src/components\": [\n",
        "            \"__init__.py\",\n",
        "            \"data_ingestion.py\",\n",
        "            \"data_transformation.py\",\n",
        "            \"model_trainer.py\"\n",
        "        ],\n",
        "        \"src/pipeline\": [\n",
        "            \"__init__.py\",\n",
        "            \"predict_pipeline.py\",\n",
        "            \"train_pipeline.py\"\n",
        "        ],\n",
        "        \"notebooks\": [],\n",
        "        \"\": [  # Base directory\n",
        "            \"import_data.py\",\n",
        "            \"setup.py\",\n",
        "            \"requirements.txt\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    # Create directories and files\n",
        "    for folder, files in directories.items():\n",
        "        folder_path = os.path.join(base_dir, folder)\n",
        "        os.makedirs(folder_path, exist_ok=True)\n",
        "        for file in files:\n",
        "            open(os.path.join(folder_path, file), 'w').close()\n",
        "\n",
        "    print(f\"Project structure created at: {os.path.abspath(base_dir)}\")\n",
        "\n",
        "# Specify base directory name\n",
        "base_directory = \"ml_project\"\n",
        "\n",
        "# Call the function\n",
        "create_ml_project_structure(base_directory)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcMK2_n1xPjl",
        "outputId": "75f7f74e-5f56-4582-8814-20a0c9893520"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Project structure created at: /content/ml_project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After Running the Script\n",
        "Initialize Git Repository:\n",
        "\n",
        "Open a terminal or command prompt.\n",
        "Navigate to the ml_project directory using"
      ],
      "metadata": {
        "id": "_BwG91v88Qji"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. Write the program for setup.py and the relevant dependencies in requirements.txt and generate egg.info folder\n",
        "\n",
        "Answer:\n",
        "\n"
      ],
      "metadata": {
        "id": "u0vv2mvt8gdi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Create setup.py\n",
        "from setuptools import setup, find_packages\n",
        "\n",
        "setup(\n",
        "    name=\"your_package_name\",\n",
        "    version=\"0.1.0\",\n",
        "    description=\"A brief description of your package\",\n",
        "    author=\"Your Name\",\n",
        "    author_email=\"your_email@example.com\",\n",
        "    url=\"https://github.com/yourusername/your-repo-name\",\n",
        "    packages=find_packages(),\n",
        "    install_requires=[\n",
        "        \"numpy>=1.21.0\",  # Example dependency\n",
        "        \"pandas>=1.3.0\",  # Example dependency\n",
        "    ],\n",
        "    classifiers=[\n",
        "        \"Programming Language :: Python :: 3\",\n",
        "        \"License :: OSI Approved :: MIT License\",\n",
        "        \"Operating System :: OS Independent\",\n",
        "    ],\n",
        "    python_requires=\">=3.6\",\n",
        ")\n"
      ],
      "metadata": {
        "id": "x5k102V89BHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5. Write the logging function in logger.py and exception function in exception.py file to be used for the project to track the progress when the ML project is run and to raise any exception when encountered.\n",
        "\n",
        "Answer:\n",
        "\n"
      ],
      "metadata": {
        "id": "p6aca_4f9hrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# logger.py\n",
        "import logging\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "def setup_logger(name: str, log_dir: str = \"logs\") -> logging.Logger:\n",
        "    \"\"\"\n",
        "    Configures and returns a logger.\n",
        "\n",
        "    Args:\n",
        "        name (str): The name of the logger.\n",
        "        log_dir (str): The directory where logs will be stored.\n",
        "\n",
        "    Returns:\n",
        "        logging.Logger: Configured logger.\n",
        "    \"\"\"\n",
        "    # Ensure the log directory exists\n",
        "    if not os.path.exists(log_dir):\n",
        "        os.makedirs(log_dir)\n",
        "\n",
        "    # Create a log file with a timestamp\n",
        "    log_file = os.path.join(log_dir, f\"{name}_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.log\")\n",
        "\n",
        "    # Configure logging\n",
        "    logging.basicConfig(\n",
        "        level=logging.INFO,\n",
        "        format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
        "        handlers=[\n",
        "            logging.FileHandler(log_file),\n",
        "            logging.StreamHandler()  # Optional: Outputs logs to the console\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Return the logger\n",
        "    logger = logging.getLogger(name)\n",
        "    return logger\n",
        "\n"
      ],
      "metadata": {
        "id": "x-DXVuMx8R9T"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How to Use\n",
        "from logger import setup_logger\n",
        "\n",
        "# Initialize the logger\n",
        "logger = setup_logger(\"ML_Project\")\n",
        "\n",
        "# Example usage\n",
        "logger.info(\"This is an info message.\")\n",
        "logger.error(\"This is an error message.\")\n"
      ],
      "metadata": {
        "id": "4idGkDxcfUBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# exception.py\n",
        "import sys\n",
        "\n",
        "class CustomException(Exception):\n",
        "    \"\"\"\n",
        "    A custom exception class to capture and raise errors with detailed messages.\n",
        "    \"\"\"\n",
        "    def __init__(self, message: str, original_exception: Exception = None):\n",
        "        super().__init__(message)\n",
        "        self.original_exception = original_exception\n",
        "\n",
        "    def __str__(self):\n",
        "        if self.original_exception:\n",
        "            return f\"{self.message} | Original Exception: {str(self.original_exception)}\"\n",
        "        return self.message\n",
        "\n",
        "def log_exception(logger, exception: Exception, context: str = \"\"):\n",
        "    \"\"\"\n",
        "    Logs the exception details with context using the provided logger.\n",
        "\n",
        "    Args:\n",
        "        logger: A logger instance to log the exception details.\n",
        "        exception: The exception instance.\n",
        "        context (str): Additional context about where the exception occurred.\n",
        "    \"\"\"\n",
        "    exc_type, exc_obj, exc_tb = sys.exc_info()\n",
        "    filename = exc_tb.tb_frame.f_code.co_filename\n",
        "    logger.error(f\"Exception occurred in {filename}, line {exc_tb.tb_lineno}, context: {context}\")\n",
        "    logger.error(f\"Exception message: {str(exception)}\")\n"
      ],
      "metadata": {
        "id": "Q7YI2q7_fVYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How to Use\n",
        "from exception import CustomException, log_exception\n",
        "from logger import setup_logger\n",
        "\n",
        "logger = setup_logger(\"ML_Project\")\n",
        "\n",
        "try:\n",
        "    # Simulate an error\n",
        "    raise ValueError(\"This is a test error.\")\n",
        "except ValueError as e:\n",
        "    log_exception(logger, e, context=\"Testing exception logging.\")\n",
        "    raise CustomException(\"A custom exception occurred\", e)\n"
      ],
      "metadata": {
        "id": "wL9MBa63fnFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7. In the notebook folder create a jupyter notebook inside it and do the following with the dataset\"\n",
        "\n",
        "Exploratory Data Analysis\n",
        "\n",
        "Feature Engineerin:\n",
        "\n",
        "Model Trainin:\n",
        "\n",
        "Selection of best model using metric,\n",
        "\n",
        "Answer:\n",
        "\n",
        "Steps in Jupyter Notebook:\n",
        "\n",
        "1. Exploratory Data Analysis (EDA)\n",
        "\n",
        "Load the dataset using pandas.\n",
        "\n",
        "Perform basic data checks:\n",
        "\n",
        "Check for null values.\n",
        "\n",
        "View data types and basic statistics (df.info(), df.describe()).\n",
        "\n",
        "Visualize data distributions and relationships using:\n",
        "\n",
        "Histograms.\n",
        "\n",
        "Pairplots or scatter plots.\n",
        "\n",
        "Correlation heatmap using seaborn.heatmap.\n",
        "\n",
        "2. Feature Engineering\n",
        "\n",
        "Handle missing values (e.g., imputation or dropping).\n",
        "\n",
        "Encode categorical variables (e.g., one-hot or label encoding).\n",
        "\n",
        "Scale numeric features (e.g., StandardScaler, MinMaxScaler).\n",
        "\n",
        "Create new features if relevant to improve model accuracy.\n",
        "\n",
        "3. Model Training\n",
        "\n",
        "Split the data into training and test sets (train_test_split).\n",
        "\n",
        "Train multiple models (e.g., Logistic Regression, Decision Trees, Random Forests) using sklearn.\n",
        "\n",
        "Evaluate models using cross-validation.\n",
        "\n",
        "4. Selection of Best Model\n",
        "\n",
        "Use metrics like accuracy, precision, recall, F1 score, or AUC-ROC (for classification).\n",
        "\n",
        "For regression tasks, use RMSE, MAE, or R²."
      ],
      "metadata": {
        "id": "E6yHKzY4gOZl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# 1. Exploratory Data Analysis\n",
        "# Load dataset\n",
        "df = pd.read_csv('dataset.csv')\n",
        "\n",
        "# Check for missing values and data types\n",
        "print(df.info())\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Visualize distributions and relationships\n",
        "sns.pairplot(df, diag_kind='kde')\n",
        "plt.show()\n",
        "\n",
        "# Heatmap for correlations\n",
        "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
        "plt.show()\n",
        "\n",
        "# 2. Feature Engineering\n",
        "# Handle missing values (example: fillna)\n",
        "df.fillna(df.mean(), inplace=True)\n",
        "\n",
        "# Encode categorical features\n",
        "label_encoder = LabelEncoder()\n",
        "df['Category'] = label_encoder.fit_transform(df['Category'])\n",
        "\n",
        "# Scale numeric features\n",
        "scaler = StandardScaler()\n",
        "df_scaled = scaler.fit_transform(df.select_dtypes(include=np.number))\n",
        "\n",
        "# 3. Model Training\n",
        "X = df_scaled\n",
        "y = df['target']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Random Forest model\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 4. Evaluate Model\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Cross-validation score\n",
        "cv_scores = cross_val_score(model, X, y, cv=5)\n",
        "print(\"Cross-validation scores:\", cv_scores)\n",
        "print(\"Mean CV Score:\", np.mean(cv_scores))\n"
      ],
      "metadata": {
        "id": "oYVrxj8UhJKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next Steps:\n",
        "\n",
        "Refine EDA: Explore advanced visualizations or insights.\n",
        "\n",
        "Tune Models: Use GridSearchCV or RandomizedSearchCV for hyperparameter tuning.\n",
        "\n",
        "Save the Best Model: Serialize with joblib or pickle."
      ],
      "metadata": {
        "id": "OQDr7VF1iCFs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q 8. Write a separate python program in import_data.py file to load the mentioned dataset from sklearn.load_dataset.load_breast_cancer to your MongoDB\n",
        "\n",
        "Answer:"
      ],
      "metadata": {
        "id": "L8goB_k_iFqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from pymongo import MongoClient\n",
        "import pandas as pd\n",
        "\n",
        "def load_dataset_to_mongodb():\n",
        "    # Load the dataset from sklearn\n",
        "    data = load_breast_cancer()\n",
        "    df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "    df['target'] = data.target\n",
        "\n",
        "    # Establish MongoDB connection\n",
        "    try:\n",
        "        client = MongoClient(\"mongodb://localhost:27017/\")  # Replace with your MongoDB URI if necessary\n",
        "        db = client[\"breast_cancer_db\"]  # Database name\n",
        "        collection = db[\"breast_cancer_data\"]  # Collection name\n",
        "\n",
        "        # Convert DataFrame to dictionary and insert into MongoDB\n",
        "        data_dict = df.to_dict(\"records\")\n",
        "        collection.insert_many(data_dict)\n",
        "        print(f\"Inserted {len(data_dict)} records into MongoDB!\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "    finally:\n",
        "        client.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    load_dataset_to_mongodb()\n"
      ],
      "metadata": {
        "id": "jkOaeWX6i9Mk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. In data_ingestion.py write a program to load the same dataset from the MongoDB to your system in DataFrame format.\n",
        "\n",
        "Answer:\n",
        "\n"
      ],
      "metadata": {
        "id": "KfA5ShhVjj8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pymongo import MongoClient\n",
        "import pandas as pd\n",
        "\n",
        "def load_data_from_mongodb():\n",
        "    # Establish MongoDB connection\n",
        "    try:\n",
        "        client = MongoClient(\"mongodb://localhost:27017/\")  # Replace with your MongoDB URI if necessary\n",
        "        db = client[\"breast_cancer_db\"]  # Database name\n",
        "        collection = db[\"breast_cancer_data\"]  # Collection name\n",
        "\n",
        "        # Fetch data from MongoDB and convert it to a DataFrame\n",
        "        data = list(collection.find({}, {\"_id\": 0}))  # Exclude MongoDB's `_id` field\n",
        "        df = pd.DataFrame(data)\n",
        "        print(\"Data successfully loaded into DataFrame!\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None\n",
        "    finally:\n",
        "        client.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    df = load_data_from_mongodb()\n",
        "    if df is not None:\n",
        "        print(df.head())  # Print the first 5 rows to verify the data\n"
      ],
      "metadata": {
        "id": "M8vdtEb2j9mc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"breast_cancer_data.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "qq4Dayfhka20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Do the necessary feature engineering part in data_transformation.py\n",
        "\n",
        "Answer:\n",
        "\n",
        "Feature engineering involves creating new features or modifying existing ones to improve the performance of a machine learning model. Here's a step-by-step approach for implementing feature engineering in data_transformation.py:\n",
        "\n",
        "Steps to Follow for Feature Engineering\n",
        "Import Necessary Libraries: Ensure you have all the required libraries like pandas, numpy, and any others you may need.\n",
        "\n",
        "Load the Data: Read the data into a Pandas DataFrame.\n",
        "\n",
        "Data Cleaning: Handle missing values, duplicates, and irrelevant columns.\n",
        "\n",
        "Feature Creation:\n",
        "\n",
        "Combine features (e.g., total price = quantity × price).\n",
        "Extract new features (e.g., extract day, month, year from a datetime column).\n",
        "Apply domain-specific transformations.\n",
        "Feature Transformation:\n",
        "\n",
        "Normalize or standardize numerical features.\n",
        "Encode categorical variables using techniques like one-hot encoding, label encoding, or target encoding.\n",
        "Feature Selection:\n",
        "\n",
        "Remove redundant or less relevant features.\n",
        "Use statistical tests or domain knowledge to retain only the important features.\n",
        "Save the Transformed Data: Export the transformed dataset or save it for further use."
      ],
      "metadata": {
        "id": "d1gaaznskcz7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  data_transformation.py\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "def load_data(file_path):\n",
        "    \"\"\"Load the dataset.\"\"\"\n",
        "    return pd.read_csv(file_path)\n",
        "\n",
        "def handle_missing_values(df):\n",
        "    \"\"\"Handle missing values in the dataset.\"\"\"\n",
        "    # Fill missing numerical values with the mean\n",
        "    for col in df.select_dtypes(include=[np.number]).columns:\n",
        "        df[col].fillna(df[col].mean(), inplace=True)\n",
        "\n",
        "    # Fill missing categorical values with the mode\n",
        "    for col in df.select_dtypes(include=['object']).columns:\n",
        "        df[col].fillna(df[col].mode()[0], inplace=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "def create_new_features(df):\n",
        "    \"\"\"Create new features.\"\"\"\n",
        "    if 'date' in df.columns:\n",
        "        df['year'] = pd.to_datetime(df['date']).dt.year\n",
        "        df['month'] = pd.to_datetime(df['date']).dt.month\n",
        "        df['day_of_week'] = pd.to_datetime(df['date']).dt.dayofweek\n",
        "\n",
        "    if 'quantity' in df.columns and 'price' in df.columns:\n",
        "        df['total_price'] = df['quantity'] * df['price']\n",
        "\n",
        "    return df\n",
        "\n",
        "def encode_features(df):\n",
        "    \"\"\"Encode categorical features.\"\"\"\n",
        "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "    encoder = OneHotEncoder(sparse=False, drop='first')\n",
        "\n",
        "    for col in categorical_cols:\n",
        "        encoded_data = pd.DataFrame(encoder.fit_transform(df[[col]]), columns=encoder.get_feature_names_out([col]))\n",
        "        df = pd.concat([df, encoded_data], axis=1).drop(columns=[col])\n",
        "\n",
        "    return df\n",
        "\n",
        "def scale_features(df):\n",
        "    \"\"\"Scale numerical features.\"\"\"\n",
        "    scaler = StandardScaler()\n",
        "    numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
        "    df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
        "    return df\n",
        "\n",
        "def main(file_path, output_path):\n",
        "    \"\"\"Main function for data transformation.\"\"\"\n",
        "    df = load_data(file_path)\n",
        "    df = handle_missing_values(df)\n",
        "    df = create_new_features(df)\n",
        "    df = encode_features(df)\n",
        "    df = scale_features(df)\n",
        "    df.to_csv(output_path, index=False)\n",
        "    print(\"Data transformation completed and saved!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_file = \"data.csv\"  # Replace with your dataset path\n",
        "    output_file = \"transformed_data.csv\"\n",
        "    main(input_file, output_file)\n"
      ],
      "metadata": {
        "id": "GNoV4FX3k3uL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key Points\n",
        "\n",
        "Custom Transformations: Tailor the feature engineering steps to your dataset and domain.\n",
        "\n",
        "Scalability: Use libraries like scikit-learn for large datasets.\n",
        "\n",
        "Documentation: Comment on your code to explain the rationale behind each transformation."
      ],
      "metadata": {
        "id": "jIanIEEKlMmE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q. 11. Create the Machine Learning model in model_trainer.py\n",
        "\n",
        "Answer:\n",
        "\n",
        "\n",
        "Here’s how you can create a basic machine learning model in a Python script named model_trainer.py. Below is an example of building a simple classifier using scikit-learn. Let me know if you’re working on a specific dataset or problem, and I’ll tailor this code further for your needs."
      ],
      "metadata": {
        "id": "VDP-Y7BQlO7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: A Classifier Using Scikit-Learn\n",
        "\n",
        "# model_trainer.py\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import joblib  # For saving the model\n",
        "\n",
        "def load_data():\n",
        "    \"\"\"\n",
        "    Function to load dataset.\n",
        "    Replace with your dataset loading logic.\n",
        "    \"\"\"\n",
        "    # Example data: Iris dataset\n",
        "    from sklearn.datasets import load_iris\n",
        "    iris = load_iris()\n",
        "    data = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "    data['target'] = iris.target\n",
        "    return data\n",
        "\n",
        "def preprocess_data(data):\n",
        "    \"\"\"\n",
        "    Function to preprocess the data.\n",
        "    Modify as per your needs.\n",
        "    \"\"\"\n",
        "    X = data.iloc[:, :-1]  # Features\n",
        "    y = data['target']     # Target variable\n",
        "    return train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "def train_model(X_train, y_train):\n",
        "    \"\"\"\n",
        "    Function to train a machine learning model.\n",
        "    \"\"\"\n",
        "    model = RandomForestClassifier(random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    return model\n",
        "\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    \"\"\"\n",
        "    Function to evaluate the model.\n",
        "    \"\"\"\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Model Accuracy: {accuracy:.2f}\")\n",
        "    return accuracy\n",
        "\n",
        "def save_model(model, filename=\"trained_model.pkl\"):\n",
        "    \"\"\"\n",
        "    Save the trained model to a file.\n",
        "    \"\"\"\n",
        "    joblib.dump(model, filename)\n",
        "    print(f\"Model saved to {filename}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Load and preprocess data\n",
        "    data = load_data()\n",
        "    X_train, X_test, y_train, y_test = preprocess_data(data)\n",
        "\n",
        "    # Train the model\n",
        "    model = train_model(X_train, y_train)\n",
        "\n",
        "    # Evaluate the model\n",
        "    evaluate_model(model, X_test, y_test)\n",
        "\n",
        "    # Save the model\n",
        "    save_model(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKRSYRB0lkc2",
        "outputId": "558405bd-705e-4549-98a9-b79e597b7064"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 1.00\n",
            "Model saved to trained_model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Steps in the Code:\n",
        "\n",
        "Load Data: Replace the example data loading (load_iris) with your own dataset.\n",
        "\n",
        "Preprocessing: Customize preprocessing to suit your dataset (e.g., handling missing values, scaling features).\n",
        "\n",
        "Model Training: Trains a Random Forest classifier. Replace or modify this for other algorithms like SVM, Logistic Regression, etc.\n",
        "\n",
        "Evaluation: Evaluates the model on test data using accuracy.\n",
        "\n",
        "Save the Model: Saves the trained model as a .pkl file using joblib."
      ],
      "metadata": {
        "id": "P5hFyTeHlxPs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q. 12. Use Flask to deploy your project.\n",
        "\n",
        "Answer:\n",
        "\n"
      ],
      "metadata": {
        "id": "LYhO8j3rl7AW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install Flask\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvCEXrEbmK9L",
        "outputId": "21cccbe8-0dd8-44d1-bf1a-0d5d3ed621f8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Flask in /usr/local/lib/python3.10/dist-packages (3.0.3)\n",
            "Requirement already satisfied: Werkzeug>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from Flask) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from Flask) (8.1.7)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from Flask) (1.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.1.2->Flask) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, render_template, request\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return \"Hello, World!\"\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHMMcQUBmNrz",
        "outputId": "889b0043-15aa-45dd-f117-1ecc717be15a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with stat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "python app.py\n"
      ],
      "metadata": {
        "id": "ZCXBj7HRmXKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gunicorn\n"
      ],
      "metadata": {
        "id": "5DOj9iiwmj8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gunicorn app:app\n"
      ],
      "metadata": {
        "id": "tG-IV0s_mnkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Choose Your Hosting Provider\n",
        "There are several platforms where you can deploy Flask applications, such as:\n",
        "\n",
        "Heroku (easy to use for small projects)\n",
        "AWS EC2 (more configurable)\n",
        "Google Cloud\n",
        "DigitalOcean\n",
        "PythonAnywhere (a good beginner-friendly option)\n",
        "Here is how you can deploy your Flask app to Heroku:\n",
        "\n",
        "Step 6: Deploy to Heroku\n",
        "Install Heroku CLI: Download and install the Heroku CLI from the Heroku website.\n",
        "\n",
        "Create a Procfile: A Procfile tells Heroku how to run your app. Create a file named Procfile (without an extension) and add the following line:"
      ],
      "metadata": {
        "id": "PyqSqsjDmxMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "web: gunicorn app:app\n"
      ],
      "metadata": {
        "id": "Gnh0m_tam2HU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip freeze > requirements.txt\n"
      ],
      "metadata": {
        "id": "AhhtA2q0m-4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "python-3.10.0\n"
      ],
      "metadata": {
        "id": "VOr14dkum_sy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "git init\n",
        "git add .\n",
        "git commit -m \"Initial commit\"\n"
      ],
      "metadata": {
        "id": "AwBbOIbsnG73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "heroku login\n"
      ],
      "metadata": {
        "id": "PSAgF3tenMHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "heroku create\n"
      ],
      "metadata": {
        "id": "foxbzme0nG_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "git push heroku master\n"
      ],
      "metadata": {
        "id": "CJbaBbJum_xP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}